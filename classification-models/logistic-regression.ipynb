{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from linear_algebra import dot, vector_add\n",
    "from gradient_descent import maximize_stochastic, maximize_batch\n",
    "from working_with_data import rescale\n",
    "from machine_learning import train_test_split\n",
    "from multiple_regression import estimate_beta, predict\n",
    "import math, random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1.0 / (1 + math.exp(-x))\n",
    "\n",
    "def logistic_prime(x):\n",
    "    return logistic(x) * (1 - logistic(x))\n",
    "\n",
    "def logistic_log_likelihood_i(x_i, y_i, beta):\n",
    "    if y_i == 1:\n",
    "        return math.log(logistic(dot(x_i, beta)))\n",
    "    else:\n",
    "        return math.log(1 - logistic(dot(x_i, beta)))\n",
    "\n",
    "def logistic_log_likelihood(x, y, beta):\n",
    "    return sum(logistic_log_likelihood_i(x_i, y_i, beta)\n",
    "               for x_i, y_i in zip(x, y))\n",
    "\n",
    "def logistic_log_partial_ij(x_i, y_i, beta, j):\n",
    "    \"\"\"here i is the index of the data point,\n",
    "    j the index of the derivative\"\"\"\n",
    "\n",
    "    return (y_i - logistic(dot(x_i, beta))) * x_i[j]\n",
    "    \n",
    "def logistic_log_gradient_i(x_i, y_i, beta):\n",
    "    \"\"\"the gradient of the log likelihood \n",
    "    corresponding to the i-th data point\"\"\"\n",
    "\n",
    "    return [logistic_log_partial_ij(x_i, y_i, beta, j)\n",
    "            for j, _ in enumerate(beta)]\n",
    "            \n",
    "def logistic_log_gradient(x, y, beta):\n",
    "    return reduce(vector_add,\n",
    "                  [logistic_log_gradient_i(x_i, y_i, beta)\n",
    "                   for x_i, y_i in zip(x,y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression:\n",
      "[0.2601679487014525, 0.4387919827477887, -0.42748064467062463]\n"
     ]
    }
   ],
   "source": [
    "data = [(0.7,48000,1),(1.9,48000,0),(2.5,60000,1),(4.2,63000,0),(6,76000,0),(6.5,69000,0),(7.5,76000,0),(8.1,88000,0),(8.7,83000,1),(10,83000,1),(0.8,43000,0),(1.8,60000,0),(10,79000,1),(6.1,76000,0),(1.4,50000,0),(9.1,92000,0),(5.8,75000,0),(5.2,69000,0),(1,56000,0),(6,67000,0),(4.9,74000,0),(6.4,63000,1),(6.2,82000,0),(3.3,58000,0),(9.3,90000,1),(5.5,57000,1),(9.1,102000,0),(2.4,54000,0),(8.2,65000,1),(5.3,82000,0),(9.8,107000,0),(1.8,64000,0),(0.6,46000,1),(0.8,48000,0),(8.6,84000,1),(0.6,45000,0),(0.5,30000,1),(7.3,89000,0),(2.5,48000,1),(5.6,76000,0),(7.4,77000,0),(2.7,56000,0),(0.7,48000,0),(1.2,42000,0),(0.2,32000,1),(4.7,56000,1),(2.8,44000,1),(7.6,78000,0),(1.1,63000,0),(8,79000,1),(2.7,56000,0),(6,52000,1),(4.6,56000,0),(2.5,51000,0),(5.7,71000,0),(2.9,65000,0),(1.1,33000,1),(3,62000,0),(4,71000,0),(2.4,61000,0),(7.5,75000,0),(9.7,81000,1),(3.2,62000,0),(7.9,88000,0),(4.7,44000,1),(2.5,55000,0),(1.6,41000,0),(6.7,64000,1),(6.9,66000,1),(7.9,78000,1),(8.1,102000,0),(5.3,48000,1),(8.5,66000,1),(0.2,56000,0),(6,69000,0),(7.5,77000,0),(8,86000,0),(4.4,68000,0),(4.9,75000,0),(1.5,60000,0),(2.2,50000,0),(3.4,49000,1),(4.2,70000,0),(7.7,98000,0),(8.2,85000,0),(5.4,88000,0),(0.1,46000,0),(1.5,37000,0),(6.3,86000,0),(3.7,57000,0),(8.4,85000,0),(2,42000,0),(5.8,69000,1),(2.7,64000,0),(3.1,63000,0),(1.9,48000,0),(10,72000,1),(0.2,45000,0),(8.6,95000,0),(1.5,64000,0),(9.8,95000,0),(5.3,65000,0),(7.5,80000,0),(9.9,91000,0),(9.7,50000,1),(2.8,68000,0),(3.6,58000,0),(3.9,74000,0),(4.4,76000,0),(2.5,49000,0),(7.2,81000,0),(5.2,60000,1),(2.4,62000,0),(8.9,94000,0),(2.4,63000,0),(6.8,69000,1),(6.5,77000,0),(7,86000,0),(9.4,94000,0),(7.8,72000,1),(0.2,53000,0),(10,97000,0),(5.5,65000,0),(7.7,71000,1),(8.1,66000,1),(9.8,91000,0),(8,84000,0),(2.7,55000,0),(2.8,62000,0),(9.4,79000,0),(2.5,57000,0),(7.4,70000,1),(2.1,47000,0),(5.3,62000,1),(6.3,79000,0),(6.8,58000,1),(5.7,80000,0),(2.2,61000,0),(4.8,62000,0),(3.7,64000,0),(4.1,85000,0),(2.3,51000,0),(3.5,58000,0),(0.9,43000,0),(0.9,54000,0),(4.5,74000,0),(6.5,55000,1),(4.1,41000,1),(7.1,73000,0),(1.1,66000,0),(9.1,81000,1),(8,69000,1),(7.3,72000,1),(3.3,50000,0),(3.9,58000,0),(2.6,49000,0),(1.6,78000,0),(0.7,56000,0),(2.1,36000,1),(7.5,90000,0),(4.8,59000,1),(8.9,95000,0),(6.2,72000,0),(6.3,63000,0),(9.1,100000,0),(7.3,61000,1),(5.6,74000,0),(0.5,66000,0),(1.1,59000,0),(5.1,61000,0),(6.2,70000,0),(6.6,56000,1),(6.3,76000,0),(6.5,78000,0),(5.1,59000,0),(9.5,74000,1),(4.5,64000,0),(2,54000,0),(1,52000,0),(4,69000,0),(6.5,76000,0),(3,60000,0),(4.5,63000,0),(7.8,70000,0),(3.9,60000,1),(0.8,51000,0),(4.2,78000,0),(1.1,54000,0),(6.2,60000,0),(2.9,59000,0),(2.1,52000,0),(8.2,87000,0),(4.8,73000,0),(2.2,42000,1),(9.1,98000,0),(6.5,84000,0),(6.9,73000,0),(5.1,72000,0),(9.1,69000,1),(9.8,79000,1),]\n",
    "data = map(list, data) # change tuples to lists\n",
    "\n",
    "x = [[1] + row[:2] for row in data] # each element is [1, experience, salary]\n",
    "y = [row[2] for row in data]        # each element is paid_account\n",
    "\n",
    "print \"linear regression:\"\n",
    "\n",
    "rescaled_x = rescale(x)\n",
    "beta = estimate_beta(rescaled_x, y)\n",
    "print beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression:\n",
      "beta_batch [-1.9061972272093648, 4.053123658820201, -3.8789401596847526]\n"
     ]
    }
   ],
   "source": [
    "print (\"logistic regression:\")\n",
    "\n",
    "random.seed(0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(rescaled_x, y, 0.33)\n",
    "\n",
    "# want to maximize log likelihood on the training data\n",
    "fn = partial(logistic_log_likelihood, x_train, y_train)\n",
    "gradient_fn = partial(logistic_log_gradient, x_train, y_train)\n",
    "\n",
    "# pick a random starting point\n",
    "beta_0 = [random.random() for _ in range(3)]\n",
    "\n",
    "# and maximize using gradient descent\n",
    "beta_hat = maximize_batch(fn, gradient_fn, beta_0)\n",
    "\n",
    "print \"beta_batch\", beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta stochastic [-1.9033197751322584, 4.044526554091981, -3.8697535805701797]\n"
     ]
    }
   ],
   "source": [
    "beta_0 = [random.random() for _ in range(3)]\n",
    "beta_hat = maximize_stochastic(logistic_log_likelihood_i,\n",
    "                           logistic_log_gradient_i,\n",
    "                           x_train, y_train, beta_0)\n",
    "\n",
    "print \"beta stochastic\", beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfNqgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a3b1890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = [logistic(dot(beta_hat, x_i)) for x_i in x_test]\n",
    "plt.scatter(predictions, y_test)\n",
    "plt.xlabel(\"predicted probability\")\n",
    "plt.ylabel(\"actual outcome\")\n",
    "plt.title(\"Logistic Regression Predicted vs. Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('precision', 0.9333333333333333)\n",
      "('recall', 0.8235294117647058)\n"
     ]
    }
   ],
   "source": [
    "true_positives = false_positives = true_negatives = false_negatives = 0\n",
    "\n",
    "for x_i, y_i in zip(x_test, y_test):\n",
    "    predict = logistic(dot(beta_hat, x_i))\n",
    "\n",
    "    if y_i == 1 and predict >= 0.5:  # TP: paid and we predict paid\n",
    "        true_positives += 1\n",
    "    elif y_i == 1:                   # FN: paid and we predict unpaid\n",
    "        false_negatives += 1\n",
    "    elif predict >= 0.5:             # FP: unpaid and we predict paid\n",
    "        false_positives += 1\n",
    "    else:                            # TN: unpaid and we predict unpaid\n",
    "        true_negatives += 1\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "print (\"precision\", precision)\n",
    "print (\"recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        50\n",
      "          1       0.98      0.90      0.94        50\n",
      "          2       0.91      0.98      0.94        50\n",
      "\n",
      "avg / total       0.96      0.96      0.96       150\n",
      "\n",
      "[[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  1 49]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "model = LogisticRegression()\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41498833,  1.46129739, -2.26214118, -1.0290951 ],\n",
       "       [ 0.41663969, -1.60083319,  0.57765763, -1.38553843],\n",
       "       [-1.70752515, -1.53426834,  2.47097168,  2.55538211]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95999999999999996"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(expected, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
